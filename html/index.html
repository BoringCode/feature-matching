<html>
<head>
<title>Computer Vision Assignment 01 - Hybrid Images</title>

<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>

<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>

<link rel="stylesheet" href="styles.css">

</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Bradley Rosenfeld</h1>
</div>
</div>
<div class="container">

<h2>COS 351 Assignment 02 - Feature Detection</h2>

<div style="float: right; padding: 20px; width: 45%;">
<img src="images/house/vis_dots.png" style="max-width: 100%;">
<p style="font-size: 14px">Example of features detected on a house.</p>
</div>

<p>For this project I was given the task of developing the three parts of a feature detection pipeline: finding interest points (edges), figuring out what features are important, and then matching those features to features found in an image of the same object. I found this project challenge because of my general lack of knowledge of the features available in Matlab. But once I discovered the debugging tools, work progressed much faster.</p>

<div style="clear:both"></div>

<h3>The algorithm</h3>

<p>Implementing the harris corner detector turned out to be the easiest part of the assignment. Once I discovered the imgradient function I was able to calculate Ix and Iy correctly. My algorithm was picking up points on the edges of the images, so I added some simple suppression of all the edges out to the feature_width mark. This suppression is simple in the sense that it simply ignores anything close to the edge of the image (by setting it to 0). Finding maximum values in the neighborhood turned out to be fairly simple with the use of the colfilt function which allowed me to automatically find the maximum value in a sliding 5x5 array.</p>

<p>Getting the features was extremely difficult. I had trouble figuring out how the SIFT algorithm was supposed to work. Once I figured out how to properly calculate the gradient angles, I was able to get something reasonablly close. I did end up implementing the normalize, clamp, renormalize pattern just to see how it would affect my results.</p>

<p>Matching features was easy once I figured out how to calculate the distances properly. The <a href="http://www.mathworks.com/help/matlab/ref/repmat.html">repmat</a> function was very helpful for this part of the problem.

<h3>Results</h3>

<p>I ended up using a lot of loops (especially in get_features.m). This seems to result in a very slow algorithm. Even when working with the example data set (where I only found around 100 features) it took several minutes to calculate.</p>

<p>Overall my algorithm seems to perform fairly well. It has an ok good matches to bad matches ratio. However, it completely failed on the difficult example data (most likely because of the large difference in contrast and color between the two images). I'd be interested to see how I could tune my algorithm to fix that.</p>

<table border=1>
<tr>
	<td>
		<img src="images/notre-dame/vis_dots.png" style="width:33%"><img src="images/notre-dame/vis_arrows.png" style="width:33%"><img src="images/notre-dame/eval.png" style="width:33%">
		<p>79 Good Matches. 7 Bad Matches</p>
	</td>
</tr>
<tr>
	<td>
		<img src="images/mount-rushmore/vis_dots.png" style="width:33%"><img src="images/mount-rushmore/vis_arrows.png" style="width:33%"><img src="images/mount-rushmore/eval.png" style="width:33%">
		<p>153 Good Matches. 10 Bad Matches</p>
	</td>
</tr>
<tr>
	<td>
		<img src="images/episcopal-gaudi/eval.png" style="width:33%; display: block; margin:auto;">
		<p>Fail!</p>
	</td>
</tr>
<tr>
	<td>
		<img src="images/house/vis_dots.png" style="width:50%;"><img src="images/house/vis_arrows.png" style="width:50%;">
		<p>Looking good</p>
	</td>
</tr>
</table>
</body>
</html>